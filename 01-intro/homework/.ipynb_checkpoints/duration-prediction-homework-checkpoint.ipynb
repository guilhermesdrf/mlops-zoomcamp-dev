{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d365a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89e7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22be4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6774f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2c03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename, drop_outliers = True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n",
    "    df['duration'] = df['duration'].apply(lambda x: x.total_seconds()/60)\n",
    "\n",
    "    if drop_outliers:\n",
    "        df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88814089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = read_dataframe('/home/ubuntu/mlops-zoomcamp-dev/01-intro/notebooks/data/yellow_tripdata_2022-01.parquet')\n",
    "df_val = read_dataframe('/home/ubuntu/mlops-zoomcamp-dev/01-intro/notebooks/data/yellow_tripdata_2022-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d521b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_with_outliers = read_dataframe('./data/yellow_tripdata_2022-01.parquet', drop_outliers = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad10253",
   "metadata": {},
   "source": [
    "__Q1. Downloading the data__\n",
    "  \n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2022.\n",
    "\n",
    "Read the data for January. How many columns are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ad5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2421440 entries, 0 to 2463930\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           object        \n",
      " 8   DOLocationID           object        \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      " 19  duration               float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int64(2), object(3)\n",
      "memory usage: 388.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce207cc",
   "metadata": {},
   "source": [
    "__19 columns without `duration`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58ddfc",
   "metadata": {},
   "source": [
    "__Q2. Computing duration__  \n",
    "  \n",
    "    \n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db9e317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.44530513776499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['duration'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3148fa7a",
   "metadata": {},
   "source": [
    "__Q3. Dropping outliers__  \n",
    "\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e58a00c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827547930522406"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]/df_train_with_outliers.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e031b48",
   "metadata": {},
   "source": [
    "__Q4. One-hot encoding__  \n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "Turn the dataframe into a list of dictionaries\n",
    "Fit a dictionary vectorizer\n",
    "Get a feature matrix from it\n",
    "What's the dimensionality of this matrix (number of columns)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e901272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "#numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5850b2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45a9acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037a903",
   "metadata": {},
   "source": [
    "__Q5. Training a model__  \n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "Train a plain linear regression model with default parameters\n",
    "Calculate the RMSE of the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd2341fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9396dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.986190836477672"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e605c",
   "metadata": {},
   "source": [
    "__Q6. Evaluating the model__  \n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022).\n",
    "\n",
    "What's the RMSE on validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f14aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09fb64db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.78640879016696"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06133a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
